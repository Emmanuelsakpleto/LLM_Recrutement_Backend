# -*- coding: utf-8 -*-
import os
import time
import random
from dotenv import load_dotenv
import matplotlib.pyplot as plt
import numpy as np
import google.generativeai as genai
import logging
import torch
import re
import json
from sentence_transformers import SentenceTransformer
import gc

# Configuration des logs
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# Chargement des variables d'environnement
load_dotenv()
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

if not GEMINI_API_KEY:
    raise ValueError("La cl√© API Gemini n'est pas d√©finie dans le fichier .env")

# Variable globale pour le mod√®le Sentence Transformer
_model_instance = None

def get_sentence_transformer():
    global _model_instance
    if _model_instance is None:
        # Lib√©rer la m√©moire cache CUDA si possible
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # Forcer le garbage collector
        gc.collect()
        
        # Charger le mod√®le avec des options d'optimisation m√©moire
        _model_instance = SentenceTransformer(
            'distiluse-base-multilingual-cased-v1',  # Mod√®le plus l√©ger
            device='cpu'  # Forcer l'utilisation du CPU
        )
    return _model_instance

# G√©n√©rateur intelligent de questions (fallback professionnel)
def generate_intelligent_questions(job_description, cv_data, score_result):
    """G√©n√©rateur de questions intelligent bas√© sur des templates"""
    templates = {
        "Job_Description": {
            "technical_skills": [
                "Pouvez-vous expliquer votre exp√©rience avec {skill} et comment vous l'avez utilis√©e dans vos projets pr√©c√©dents ?",
                "Quels sont les d√©fis les plus complexes que vous avez rencontr√©s avec {skill} et comment les avez-vous r√©solus ?",
                "Comment √©valuez-vous votre niveau de ma√Ætrise de {skill} et quelles sont vos perspectives d'am√©lioration ?",
                "D√©crivez un projet concret o√π {skill} a √©t√© d√©terminant pour le succ√®s de la r√©alisation.",
                "Quelles sont les meilleures pratiques que vous appliquez quand vous travaillez avec {skill} ?"
            ],
            "experience": [
                "Avec {years} ans d'exp√©rience requise, comment votre parcours vous a-t-il pr√©par√© √† ce poste ?",
                "D√©crivez une situation o√π votre exp√©rience a √©t√© cruciale pour r√©soudre un probl√®me complexe.",
                "Comment votre exp√©rience vous permet-elle d'aborder les d√©fis de ce poste de {title} ?",
                "Quels apprentissages de votre exp√©rience pass√©e souhaitez-vous appliquer dans ce r√¥le ?"
            ],
            "general": [
                "Qu'est-ce qui vous motive le plus dans un poste de {title} ?",
                "Comment voyez-vous l'√©volution de votre carri√®re dans ce domaine ?",
                "Quels sont vos objectifs professionnels √† court et moyen terme ?",
                "Comment d√©finiriez-vous un environnement de travail id√©al pour vous ?"
            ]
        },
        "Company_Culture": {
            "innovation": [
                "Comment abordez-vous l'innovation dans votre travail quotidien ?",
                "D√©crivez une situation o√π vous avez propos√© une solution innovante.",
                "Que signifie l'innovation pour vous dans un contexte professionnel ?",
                "Comment restez-vous √† jour avec les derni√®res tendances de votre domaine ?"
            ],
            "collaboration": [
                "D√©crivez votre approche du travail en √©quipe.",
                "Comment g√©rez-vous les conflits ou d√©saccords au sein d'une √©quipe ?",
                "Donnez un exemple de collaboration r√©ussie que vous avez men√©e.",
                "Quel r√¥le pr√©f√©rez-vous jouer dans une √©quipe projet ?"
            ],
            "transparency": [
                "Comment communiquez-vous sur vos difficult√©s ou erreurs ?",
                "Quelle est votre approche pour donner et recevoir du feedback ?",
                "Comment assurez-vous la transparence dans vos projets ?",
                "D√©crivez une situation o√π la transparence a √©t√© cl√© dans votre travail."
            ],
            "client_impact": [
                "Comment mesurez-vous l'impact de votre travail sur les clients ?",
                "D√©crivez une situation o√π vous avez am√©lior√© l'exp√©rience client.",
                "Quelle est votre approche pour comprendre les besoins clients ?",
                "Comment int√©grez-vous la perspective client dans vos d√©cisions ?"
            ]
        },
        "CV_Professional_Life": {
            "skills_validation": [
                "Votre CV mentionne {skill}. Pouvez-vous d√©tailler votre exp√©rience pratique avec cette technologie ?",
                "Parmi vos comp√©tences ({skills}), laquelle consid√©rez-vous comme votre point fort ?",
                "Comment avez-vous d√©velopp√© votre expertise en {skill} ?",
                "Quels projets vous ont permis d'approfondir vos comp√©tences en {skills} ?"
            ],
            "education": [
                "Comment votre formation en {education} vous a-t-elle pr√©par√© √† ce poste ?",
                "Quels aspects de votre formation appliquez-vous encore aujourd'hui ?",
                "Y a-t-il des domaines de votre formation que vous souhaitez approfondir ?",
                "Comment compl√©tez-vous votre formation initiale par l'apprentissage continu ?"
            ],
            "experience_analysis": [
                "Quel a √©t√© votre projet le plus marquant et pourquoi ?",
                "Comment avez-vous √©volu√© professionnellement ces derni√®res ann√©es ?",
                "Quels d√©fis avez-vous rencontr√©s dans votre parcours et comment les avez-vous surmont√©s ?",
                "Qu'est-ce qui vous a motiv√© √† postuler pour ce poste maintenant ?"
            ],
            "career_progression": [
                "Comment envisagez-vous la suite de votre carri√®re ?",
                "Quelles comp√©tences souhaitez-vous d√©velopper dans ce poste ?",
                "Qu'est-ce qui vous motive dans votre √©volution professionnelle ?",
                "Comment ce poste s'inscrit-il dans votre projet de carri√®re ?"
            ]
        }
    }
    
    all_questions = []
    
    # Extraction des donn√©es
    title = job_description.get("title", "ce poste")
    skills = job_description.get("skills", [])
    years = job_description.get("required_experience_years", 3)
    cv_skills = cv_data.get("Comp√©tences", [])
    education = cv_data.get("Formations", [{}])[0].get("dipl√¥me", "votre formation")
    
    # Questions Job Description (5)
    job_templates = templates["Job_Description"]
    
    # 2 questions techniques sur les comp√©tences
    if skills:
        selected_skills = random.sample(skills, min(2, len(skills)))
        for skill in selected_skills:
            template = random.choice(job_templates["technical_skills"])
            all_questions.append({
                "category": "Job Description",
                "question": template.format(skill=skill),
                "purpose": f"√âvaluer la ma√Ætrise de {skill}"
            })
    
    # 1 question sur l'exp√©rience
    exp_template = random.choice(job_templates["experience"])
    all_questions.append({
        "category": "Job Description",
        "question": exp_template.format(years=years, title=title),
        "purpose": "√âvaluer l'exp√©rience pertinente"
    })
    
    # 2 questions g√©n√©rales
    for _ in range(5 - len(all_questions)):
        gen_template = random.choice(job_templates["general"])
        all_questions.append({
            "category": "Job Description",
            "question": gen_template.format(title=title),
            "purpose": "√âvaluer la motivation et la vision"
        })
    
    # Questions Company Culture (5)
    culture_templates = templates["Company_Culture"]
    categories = ["innovation", "collaboration", "transparency", "client_impact"]
    
    for category in categories:
        template = random.choice(culture_templates[category])
        all_questions.append({
            "category": "Company Culture",
            "question": template,
            "purpose": f"√âvaluer l'ad√©quation avec la valeur {category}"
        })
    
    # Une question suppl√©mentaire al√©atoire
    random_category = random.choice(categories)
    template = random.choice(culture_templates[random_category])
    all_questions.append({
        "category": "Company Culture",
        "question": template,
        "purpose": f"Approfondir l'√©valuation de {random_category}"
    })
    
    # Questions CV/Professional Life (5)
    cv_templates = templates["CV_Professional_Life"]
    
    # 2 questions sur les comp√©tences CV
    if cv_skills:
        selected_skills = random.sample(cv_skills, min(2, len(cv_skills)))
        for skill in selected_skills:
            template = random.choice(cv_templates["skills_validation"])
            all_questions.append({
                "category": "CV/Professional Life",
                "question": template.format(skill=skill, skills=", ".join(cv_skills)),
                "purpose": f"Valider la comp√©tence {skill}"
            })
    
    # 1 question sur la formation
    edu_template = random.choice(cv_templates["education"])
    all_questions.append({
        "category": "CV/Professional Life",
        "question": edu_template.format(education=education),
        "purpose": "√âvaluer l'apport de la formation"
    })
    
    # 2 questions sur l'exp√©rience et la carri√®re
    for _ in range(5 - (len(all_questions) - 10)):  # Compl√©ter pour avoir 5 questions CV
        if len(all_questions) % 2 == 0:
            template = random.choice(cv_templates["experience_analysis"])
            purpose = "Analyser l'exp√©rience professionnelle"
        else:
            template = random.choice(cv_templates["career_progression"])
            purpose = "√âvaluer la progression de carri√®re"
        
        all_questions.append({
            "category": "CV/Professional Life",
            "question": template,
            "purpose": purpose
        })
    
    logger.info(f"‚úÖ G√©n√©rateur intelligent: {len(all_questions)} questions cr√©√©es")
    return {"questions": all_questions}

try:
    # Configuration de l'API Gemini
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-1.5-flash')
    logger.info("API Gemini configur√©e avec succ√®s")
except Exception as e:
    logger.error(f"Erreur lors de la configuration de l'API Gemini: {str(e)}")
    raise

def generate_job_description(data):
    try:
        logger.info("üöÄ D√©but de la g√©n√©ration de description")
        logger.info(f"üìù Donn√©es re√ßues: {data}")
        
        if not GEMINI_API_KEY:
            logger.error("‚ùå Cl√© API Gemini manquante")
            raise ValueError("Configuration API manquante")

        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')
        logger.info("‚úÖ API Gemini configur√©e")

        prompt = f"""
        Cr√©ez une description de poste professionnelle pour :
        - Poste : {data['title']}
        - Comp√©tences : {data['skills']}
        - Exp√©rience : {data['experience']} ans
        - Contexte : {data['description']}
        """
        
        logger.info("üì§ Envoi de la requ√™te √† Gemini")
        response = model.generate_content(prompt)
        
        if response and response.text:
            logger.info("‚úÖ Description g√©n√©r√©e avec succ√®s")
            return response.text
        else:
            logger.error("‚ùå Aucune r√©ponse de l'API")
            raise ValueError("G√©n√©ration √©chou√©e")
            
    except Exception as e:
        logger.error(f"‚ùå Erreur: {str(e)}")
        raise

# Fonctions utilitaires
def cosine_similarity(a: torch.Tensor, b: torch.Tensor) -> float:
    return torch.nn.functional.cosine_similarity(a.unsqueeze(0), b.unsqueeze(0), dim=1).item()

# D√©sactiver les avertissements de symlinks pour Hugging Face
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "true"

# Charger la cl√© API depuis .env
load_dotenv()
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
if not GEMINI_API_KEY:
    raise ValueError("Cl√© API Gemini manquante. V√©rifiez le fichier .env.")

# Configurer Gemini
genai.configure(api_key=GEMINI_API_KEY)

# Utiliser la fonction get_sentence_transformer au lieu d'une instance globale
def get_embeddings(text):
    model = get_sentence_transformer()
    return model.encode(text)

print("Configuration initiale termin√©e avec succ√®s !")

def generate_job_description(brief, model="gemini-1.5-flash"):
    try:
        gen_model = genai.GenerativeModel(model)
        prompt = f"""
        G√©n√©rez une fiche de poste structur√©e au format JSON √† partir du brief suivant : "{brief}". La fiche doit contenir :
        - "title" : Titre du poste
        - "description" : Description g√©n√©rale (100-150 mots, ton professionnel)
        - "skills" : Liste des comp√©tences requises
        - "responsibilities" : Liste des responsabilit√©s principales
        - "qualifications" : Liste des qualifications (exp√©rience, formation, etc.)
        - "required_experience_years" : Nombre d'ann√©es d'exp√©rience requises (nombre)
        - "required_degree" : Dipl√¥me requis (ex. "Bachelor", "Master")
        Retournez EXCLUSIVEMENT un seul objet JSON valide, sans texte explicatif, sans balises ```json, sans r√©p√©tition.
        """
        response = gen_model.generate_content(prompt)
        text = response.text.strip()
        json_match = re.search(r'\{[\s\S]*?\}(?=\s*\{|$)', text)
        if json_match:
            return json.loads(json_match.group(0))
        else:
            print("Erreur : Aucun JSON valide trouv√© dans la r√©ponse")
            return None
    except Exception as e:
        print(f"Erreur lors de la g√©n√©ration de la fiche de poste : {str(e)}")
        return None

def extract_text_from_pdf(pdf_path):
    try:
        import pdfplumber
        with pdfplumber.open(pdf_path) as pdf:
            text = ""
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + " "
        text = re.sub(r'\s+', ' ', text.strip())
        return text
    except Exception as e:
        return f"Erreur lors de l'extraction du PDF : {str(e)}"

def analyze_cv(cv_text, model="gemini-1.5-flash"):
    try:
        gen_model = genai.GenerativeModel(model)
        prompt = f"""
        Analyse le CV suivant et extrais les informations cl√©s sous forme de JSON structur√© :
        - Comp√©tences : liste de cha√Ænes (ex. ["Python", "Java"])
        - Exp√©riences professionnelles : liste d'objets avec poste, entreprise, dur√©e, description
        - Formations : liste d'objets avec dipl√¥me, institution, ann√©e
        CV : {cv_text}
        Retourne UNIQUEMENT un JSON valide, sans texte suppl√©mentaire, sans balises markdown.
        """
        response = gen_model.generate_content(prompt)
        cleaned_response = re.sub(r'^```json\n|```$', '', response.text, flags=re.MULTILINE).strip()
        return json.loads(cleaned_response)
    except json.JSONDecodeError as e:
        return {"error": f"Impossible de parser la r√©ponse en JSON : {str(e)}", "raw_response": response.text}
    except Exception as e:
        return {"error": f"Erreur lors de l'analyse avec Gemini : {str(e)}"}

def calculate_cv_score(cv_data, job_description):
    try:
        logger.info(f"üéØ Calcul du score CV - CV data: {cv_data}")
        logger.info(f"üéØ Calcul du score CV - Job desc: {job_description}")
        
        skills_score = 0.0
        experience_score = 0.0
        education_score = 0.0       
        cv_skills = cv_data.get("Comp√©tences", [])
        job_skills = job_description.get("skills", [])
        
        logger.info(f"üîß CV skills: {cv_skills}")
        logger.info(f"üîß Job skills: {job_skills}")
        
        if cv_skills and job_skills:
            # Utiliser get_embeddings avec conversion en tenseur PyTorch
            cv_embeddings = torch.tensor(get_embeddings(cv_skills))
            job_embeddings = torch.tensor(get_embeddings(job_skills))
            
            logger.info(f"üìä CV embeddings shape: {cv_embeddings.shape}")
            logger.info(f"üìä Job embeddings shape: {job_embeddings.shape}")
            
            # Calculer les similarit√©s individuelles
            similarities = []
            for cv_emb in cv_embeddings:
                skill_similarities = []
                for job_emb in job_embeddings:
                    similarity = cosine_similarity(cv_emb, job_emb)
                    skill_similarities.append(similarity)
                similarities.append(max(skill_similarities))
            
            # Calculer le score moyen
            skills_score = sum(similarities) / len(similarities) if similarities else 0.0
            logger.info(f"üéØ Skills score calcul√©: {skills_score}")

        cv_experiences = cv_data.get("Exp√©riences professionnelles", [])
        required_years = job_description.get("required_experience_years", 0)
        logger.info(f"üíº CV experiences: {cv_experiences}")
        logger.info(f"üíº Required years: {required_years}")
        
        if cv_experiences:
            total_years = 0
            for exp in cv_experiences:
                duration = exp.get("dur√©e", "").lower()
                if "ans" in duration or "an" in duration:
                    match = re.search(r'(\d+\.?\d*)', duration)
                    if match:
                        total_years += float(match.group(1))
                elif "mois" in duration:
                    match = re.search(r'(\d+\.?\d*)', duration)
                    if match:
                        total_years += float(match.group(1)) / 12
                elif "-" in duration:
                    months = 2
                    total_years += months / 12
            
            # Gestion sp√©ciale pour les postes de stagiaire (0 ans requis)
            if required_years == 0:
                # Pour un poste de stagiaire, toute exp√©rience est un bonus
                # Score bas√© sur l'exp√©rience existante (plafonn√© √† 100%)
                experience_score = min(total_years * 0.5, 1.0)  # 2 ans d'exp√©rience = score maximum
                logger.info(f"üíº Poste de stagiaire d√©tect√© - Bonus d'exp√©rience appliqu√©")
            else:
                # Calcul normal pour les postes avec exp√©rience requise
                experience_score = min(total_years / required_years, 1.0)
            
            logger.info(f"üíº Total years calculated: {total_years}")
            logger.info(f"üíº Experience score: {experience_score}")
        else:
            # Aucune exp√©rience dans le CV
            if required_years == 0:
                # Pour un poste de stagiaire sans exp√©rience requise, c'est acceptable
                experience_score = 0.8  # Score de base pour un stagiaire sans exp√©rience
                logger.info(f"üíº Poste de stagiaire sans exp√©rience - Score de base appliqu√©")
            else:
                experience_score = 0.0
                logger.info(f"üíº Aucune exp√©rience trouv√©e")

        cv_educations = cv_data.get("Formations", [])
        required_degree = job_description.get("required_degree", "")
        logger.info(f"üéì CV educations: {cv_educations}")
        logger.info(f"üéì Required degree: {required_degree}")
        
        if cv_educations and required_degree:
            degree_levels = {"Bac": 1, "Licence": 2, "Bachelor": 2, "Master": 3, "Doctorat": 4}
            max_cv_degree_level = 0
            for edu in cv_educations:
                degree = edu.get("dipl√¥me", "")
                for deg, level in degree_levels.items():
                    if deg.lower() in degree.lower():
                        max_cv_degree_level = max(max_cv_degree_level, level)
            required_level = degree_levels.get(required_degree, 1)
            education_score = min(max_cv_degree_level / required_level, 1.0) if required_level > 0 else 0.0
            logger.info(f"üéì Max degree level: {max_cv_degree_level}")
            logger.info(f"üéì Required level: {required_level}")
            logger.info(f"üéì Education score: {education_score}")

        final_score = (0.5 * skills_score + 0.3 * experience_score + 0.2 * education_score) * 100
        
        logger.info(f"üèÜ Final score components:")
        logger.info(f"   - Skills: {skills_score * 100}%")
        logger.info(f"   - Experience: {experience_score * 100}%") 
        logger.info(f"   - Education: {education_score * 100}%")
        logger.info(f"   - Final: {final_score}%")

        result = {
            "skills_score": skills_score * 100,
            "experience_score": experience_score * 100,
            "education_score": education_score * 100,
            "final_score": final_score
        }
        
        logger.info(f"üéØ Returning score result: {result}")
        return result
    except Exception as e:
        return {"error": f"Erreur lors du calcul du score : {str(e)}"}

def visualize_scores(score_result):
    if "error" in score_result:
        print("Visualisation impossible : scores non calcul√©s.")
        return

    labels = ["Comp√©tences", "Exp√©rience", "Formation", "Final"]
    scores = [
        score_result["skills_score"],
        score_result["experience_score"],
        score_result["education_score"],
        score_result["final_score"]
    ]

    plt.figure(figsize=(8, 6))
    plt.bar(labels, scores, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
    plt.ylim(0, 100)
    plt.title("√âvaluation du CV par rapport √† la fiche de poste", fontsize=14)
    plt.ylabel("Score (%)", fontsize=12)
    for i, score in enumerate(scores):
        plt.text(i, score + 2, f"{score:.1f}%", ha="center", fontsize=10)
    plt.tight_layout()
    plt.savefig("cv_scores.png")  # Sauvegarde pour le frontend
    plt.close()

def generate_final_report(cv_text, cv_data, score_result, job_description):
    try:
        skills_count = len(cv_data.get("Comp√©tences", []))
        exp_count = len(cv_data.get("Exp√©riences professionnelles", []))
        edu_count = len(cv_data.get("Formations", []))
        summary = (
            f"### R√©sum√© de l'√âvaluation du CV\n\n"
            f"- **Poste vis√©** : {job_description.get('title', 'Non sp√©cifi√©')}\n"
            f"- **Comp√©tences** : {skills_count} comp√©tences identifi√©es ({', '.join(cv_data.get('Comp√©tences', [])[:3]) + '...' if skills_count > 3 else ', '.join(cv_data.get('Comp√©tences', []))}). Score : {score_result.get('skills_score', 0):.1f}%\n"
            f"- **Exp√©riences** : {exp_count} exp√©riences, principalement dans {cv_data.get('Exp√©riences professionnelles', [{}])[0].get('description', 'divers domaines')[:50]}... Score : {score_result.get('experience_score', 0):.1f}%\n"
            f"- **Formations** : {edu_count} formations, incluant {cv_data.get('Formations', [{}])[0].get('dipl√¥me', 'aucun dipl√¥me')} ({cv_data.get('Formations', [{}])[0].get('institution', '')}). Score : {score_result.get('education_score', 0):.1f}%\n"
            f"- **Score final** : {score_result.get('final_score', 0):.1f}%\n\n"
            f"**Conclusion** : Le candidat pr√©sente {'une excellente' if score_result.get('final_score', 0) > 80 else 'une bonne' if score_result.get('final_score', 0) > 60 else 'une certaine'} ad√©quation avec le poste, avec des comp√©tences techniques solides et une formation pertinente. {'Continuer l‚Äô√©valuation pour un entretien.' if score_result.get('final_score', 0) > 60 else 'Consid√©rer pour des postes similaires avec moins d‚Äôexp√©rience.'}"
        )

        final_output = {
            "cv_text": cv_text[:500] + "..." if len(cv_text) > 500 else cv_text,
            "extracted_cv_data": cv_data,
            "job_description": job_description,
            "scores": score_result,
            "summary": summary
        }

        with open("recruitment_report.json", "w", encoding="utf-8") as f:
            json.dump(final_output, f, indent=2, ensure_ascii=False)

        return final_output
    except Exception as e:
        return {"error": f"Erreur lors de la g√©n√©ration du rapport : {str(e)}"}

def generate_questions_for_category(prompt, category, model="gemini-1.5-flash", max_attempts=3):
    gen_model = genai.GenerativeModel(model)
    for attempt in range(max_attempts):
        try:
            logger.info(f"üéØ G√©n√©ration questions pour {category} (tentative {attempt + 1})")
            response = gen_model.generate_content(prompt)
            raw_response = response.text.strip()
            
            # Sauvegarder la r√©ponse pour debug
            with open(f"debug_response_{category}.txt", "w", encoding="utf-8") as f:
                f.write(raw_response)
            
            logger.info(f"üìù R√©ponse brute pour {category}: {raw_response[:200]}...")

            # Nettoyer la r√©ponse en supprimant les balises markdown
            cleaned_response = re.sub(r'^```json\n|```$', '', raw_response, flags=re.MULTILINE).strip()
            
            # Chercher le JSON
            json_match = re.search(r'\{[\s\S]*\}', cleaned_response)
            if not json_match:
                logger.warning(f"‚ö†Ô∏è Tentative {attempt + 1} ({category}): Aucun JSON valide trouv√©")
                if attempt < max_attempts - 1:
                    time.sleep(2)
                    continue
                logger.error(f"‚ùå √âchec final pour {category}: Aucun JSON valide")
                return None

            # Parser le JSON
            questions_data = json.loads(json_match.group(0))
            questions = questions_data.get("questions", [])
            
            logger.info(f"üìä {len(questions)} questions trouv√©es pour {category}")
            
            if len(questions) != 5:
                logger.warning(f"‚ö†Ô∏è Tentative {attempt + 1} ({category}): {len(questions)} questions au lieu de 5")
                if attempt < max_attempts - 1:
                    time.sleep(2)
                    continue
                logger.error(f"‚ùå √âchec final pour {category}: Nombre incorrect de questions")
                return None

            logger.info(f"‚úÖ Questions g√©n√©r√©es avec succ√®s pour {category}")
            return questions
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Tentative {attempt + 1} ({category}): Erreur JSON : {str(e)}")
            if attempt < max_attempts - 1:
                time.sleep(2)
                continue
            logger.error(f"‚ùå √âchec final pour {category}: Erreur JSON")
            return None
        except Exception as e:
            logger.error(f"‚ùå Tentative {attempt + 1} ({category}): Erreur g√©n√©rale : {str(e)}")
            if attempt < max_attempts - 1:
                time.sleep(2)
                continue
            logger.error(f"‚ùå √âchec final pour {category}: Erreur g√©n√©rale")
            return None
    
    logger.error(f"‚ùå √âchec complet pour {category} apr√®s {max_attempts} tentatives")
    return None

def generate_interview_questions(job_description, cv_data, score_result, model="gemini-1.5-flash"):
    try:
        if not job_description or "error" in cv_data or "error" in score_result:
            return {"error": "Donn√©es manquantes ou invalides."}

        job_title = job_description.get("title", "D√©veloppeur Python")
        job_skills = ", ".join(job_description.get("skills", []))
        required_years = job_description.get("required_experience_years", 3)
        cv_skills = ", ".join(cv_data.get("Comp√©tences", []))
        cv_education = cv_data.get("Formations", [{}])[0].get("dipl√¥me", "Non sp√©cifi√©")
        experience_score = score_result.get("experience_score", 0)

        company_context = "TechNova est une startup SaaS ax√©e sur l‚Äôinnovation, la collaboration, la transparence et l‚Äôimpact client."

        prompts = {
            "Job_Description": f"""
            Cr√©ez exactement 5 questions d'entretien RH pour √©valuer un candidat au poste de {job_title}.
            Comp√©tences requises: {job_skills}
            Exp√©rience requise: {required_years} ans
            
            Retournez UNIQUEMENT un JSON avec cette structure exacte:
            {{
                "questions": [
                    {{"category": "Job Description", "question": "Question technique 1?", "purpose": "√âvaluer comp√©tence X"}},
                    {{"category": "Job Description", "question": "Question technique 2?", "purpose": "√âvaluer comp√©tence Y"}},
                    {{"category": "Job Description", "question": "Question technique 3?", "purpose": "√âvaluer comp√©tence Z"}},
                    {{"category": "Job Description", "question": "Question technique 4?", "purpose": "√âvaluer exp√©rience"}},
                    {{"category": "Job Description", "question": "Question technique 5?", "purpose": "√âvaluer approche"}}
                ]
            }}
            """,
            "Company_Culture": f"""
            Cr√©ez exactement 5 questions d'entretien RH pour √©valuer l'ad√©quation culturelle d'un candidat.
            Contexte entreprise: {company_context}
            
            Retournez UNIQUEMENT un JSON avec cette structure exacte:
            {{
                "questions": [
                    {{"category": "Company Culture", "question": "Question culture 1?", "purpose": "√âvaluer valeur innovation"}},
                    {{"category": "Company Culture", "question": "Question culture 2?", "purpose": "√âvaluer collaboration"}},
                    {{"category": "Company Culture", "question": "Question culture 3?", "purpose": "√âvaluer transparence"}},
                    {{"category": "Company Culture", "question": "Question culture 4?", "purpose": "√âvaluer impact client"}},
                    {{"category": "Company Culture", "question": "Question culture 5?", "purpose": "√âvaluer adaptation"}}
                ]
            }}
            """,
            "CV_Professional_Life": f"""
            Cr√©ez exactement 5 questions d'entretien RH bas√©es sur le profil du candidat.
            Comp√©tences candidat: {cv_skills}
            Formation: {cv_education}
            Score d'exp√©rience: {experience_score:.1f}%
            
            Retournez UNIQUEMENT un JSON avec cette structure exacte:
            {{
                "questions": [
                    {{"category": "CV/Professional Life", "question": "Question exp√©rience 1?", "purpose": "Approfondir exp√©rience"}},
                    {{"category": "CV/Professional Life", "question": "Question exp√©rience 2?", "purpose": "Valider comp√©tences"}},
                    {{"category": "CV/Professional Life", "question": "Question exp√©rience 3?", "purpose": "Comprendre projets"}},
                    {{"category": "CV/Professional Life", "question": "Question exp√©rience 4?", "purpose": "√âvaluer formation"}},
                    {{"category": "CV/Professional Life", "question": "Question exp√©rience 5?", "purpose": "Mesurer ambition"}}
                ]
            }}
            """
        }

        all_questions = []
        
        # Tentative de g√©n√©ration avec l'API Gemini
        try:
            logger.info("üöÄ Tentative de g√©n√©ration avec l'API Gemini")
            for category in prompts:
                questions = generate_questions_for_category(prompts[category], category.replace("/", "_"), model)
                if questions is None:
                    logger.warning(f"‚ö†Ô∏è √âchec API pour {category}, utilisation du g√©n√©rateur intelligent")
                    # En cas d'√©chec d'une cat√©gorie, utiliser le g√©n√©rateur intelligent
                    intelligent_result = generate_intelligent_questions(job_description, cv_data, score_result)
                    logger.info("‚úÖ Questions intelligentes g√©n√©r√©es avec succ√®s")
                    return intelligent_result
                all_questions.extend(questions)

            if len(all_questions) != 15:
                logger.warning(f"‚ö†Ô∏è Nombre incorrect de questions ({len(all_questions)}), utilisation du g√©n√©rateur intelligent")
                intelligent_result = generate_intelligent_questions(job_description, cv_data, score_result)
                logger.info("‚úÖ Questions intelligentes g√©n√©r√©es avec succ√®s")
                return intelligent_result
                
            logger.info("‚úÖ Questions API g√©n√©r√©es avec succ√®s")
            
        except Exception as api_error:
            logger.error(f"‚ùå Erreur API Gemini: {str(api_error)}")
            logger.info("üîÑ Basculement vers le g√©n√©rateur intelligent")
            intelligent_result = generate_intelligent_questions(job_description, cv_data, score_result)
            logger.info("‚úÖ Questions intelligentes g√©n√©r√©es avec succ√®s")
            return intelligent_result

        questions_data = {"questions": all_questions}

        with open("interview_questions.json", "w", encoding="utf-8") as f:
            json.dump(questions_data, f, indent=2, ensure_ascii=False)

        return questions_data
    except Exception as e:
        logger.error(f"‚ùå Erreur g√©n√©rale dans generate_interview_questions: {str(e)}")
        # Dernier recours : g√©n√©rateur intelligent m√™me en cas d'erreur g√©n√©rale
        try:
            intelligent_result = generate_intelligent_questions(job_description, cv_data, score_result)
            logger.info("‚úÖ Questions intelligentes g√©n√©r√©es en dernier recours")
            return intelligent_result
        except Exception as fallback_error:
            logger.error(f"‚ùå √âchec complet, m√™me le g√©n√©rateur intelligent: {str(fallback_error)}")
            return {"error": f"Erreur g√©n√©rale : {str(e)}"}

def collect_rh_appreciations(questions_data):
    valid_appreciations = {
        "tr√®s insatisfait": 0,
        "insatisfait": 25,
        "satisfait": 75,
        "tr√®s satisfait": 100
    }
    appreciations = []

    print("Entrez une appr√©ciation pour chaque question (tr√®s insatisfait, insatisfait, satisfait, tr√®s satisfait).")
    for q in questions_data["questions"]:
        while True:
            print(f"\nQuestion ({q['category']}) : {q['question']}")
            appreciation = input("Appr√©ciation : ").strip().lower()
            if appreciation in valid_appreciations:
                appreciations.append({
                    "question": q["question"],
                    "category": q["category"],
                    "appreciation": appreciation,
                    "score": valid_appreciations[appreciation]
                })
                break
            print("Entr√©e invalide. Options : tr√®s insatisfait, insatisfait, satisfait, tr√®s satisfait.")

    return appreciations

def generate_predictive_analysis(job_description, cv_data, score_result, questions_data, appreciations_data=None, model="gemini-1.5-flash", max_attempts=3):
    try:
        if not job_description or "error" in cv_data or "error" in score_result or not questions_data:
            return {"error": "Donn√©es manquantes ou invalides."}

        gen_model = genai.GenerativeModel(model)

        # Utiliser les appr√©ciations transmises ou les collecter interactivement
        if appreciations_data:
            appreciations = appreciations_data
        else:
            appreciations = collect_rh_appreciations(questions_data)

        interview_score = [a["score"] for a in appreciations]
        interview_avg = sum(interview_score) / len(interview_score)
        culture_scores = [a["score"] for a in appreciations if a["category"] == "Company Culture"]
        culture_avg = sum(culture_scores) / len(culture_scores) if culture_scores else 50.0

        job_title = job_description.get("title", "D√©veloppeur Python")
        job_skills = ", ".join(job_description.get("skills", []))
        required_years = job_description.get("required_experience_years", 3)
        cv_skills = ", ".join(cv_data.get("Comp√©tences", []))
        cv_education = cv_data.get("Formations", [{}])[0].get("dipl√¥me", "Non sp√©cifi√©")
        scores = score_result
        company_context = "TechNova valorise l‚Äôinnovation, la collaboration, la transparence, et l‚Äôimpact client."

        prompt = f"""
        Effectuez une analyse des risques et recommandations d‚Äôonboarding pour un candidat au poste de {job_title}.
        Donn√©es :
        - Fiche de poste : Comp√©tences ({job_skills}), {required_years} ans d‚Äôexp√©rience.
        - CV : Comp√©tences ({cv_skills}), Formation ({cv_education}).
        - Scores : Comp√©tences ({scores.get('skills_score', 0):.1f}%), Exp√©rience ({scores.get('experience_score', 0):.1f}%), Formation ({scores.get('education_score', 0):.1f}%).
        - Note d‚Äôentretien : {interview_avg:.1f}% (bas√©e sur appr√©ciations RH).
        Retournez un JSON avec :
        - "risks" (liste de 2-3 risques cl√©s).
        - "recommendations" (liste de 3-5 recommandations d‚Äôonboarding : formations, mentoring, objectifs 30/60/90 jours).
        JSON valide uniquement.
        """

        for attempt in range(max_attempts):
            try:
                response = gen_model.generate_content(prompt)
                raw_response = response.text.strip()
                with open("debug_analysis_response.txt", "w", encoding="utf-8") as f:
                    f.write(raw_response)
                print(f"R√©ponse brute de l‚ÄôAPI (tentative {attempt + 1}) : {raw_response[:500]}...")

                json_match = re.search(r'\{[\s\S]*\}', raw_response)
                if not json_match:
                    print(f"Tentative {attempt + 1} : Aucun JSON valide.")
                    if attempt < max_attempts - 1:
                        time.sleep(2)
                        continue
                    return {"error": "Aucun JSON valide apr√®s plusieurs tentatives."}

                analysis = json.loads(json_match.group(0))
                if not all(key in analysis for key in ["risks", "recommendations"]):
                    print(f"Tentative {attempt + 1} : JSON incomplet.")
                    if attempt < max_attempts - 1:
                        time.sleep(2)
                        continue
                    return {"error": "JSON incomplet apr√®s plusieurs tentatives."}

                break
            except json.JSONDecodeError as e:
                print(f"Tentative {attempt + 1} : Erreur JSON : {str(e)}")
                if attempt < max_attempts - 1:
                    time.sleep(2)
                    continue
                return {"error": f"Erreur JSON apr√®s {max_attempts} tentatives : {str(e)}"}
            except Exception as e:
                print(f"Tentative {attempt + 1} : Erreur : {str(e)}")
                if attempt < max_attempts - 1:
                    time.sleep(2)
                    continue
                return {"error": f"Erreur API apr√®s {max_attempts} tentatives : {str(e)}"}

        predictive_score = (
            0.30 * scores.get("skills_score", 0) +
            0.25 * scores.get("experience_score", 0) +
            0.25 * interview_avg +
            0.10 * scores.get("education_score", 0) +
            0.10 * culture_avg
        )

        radar_data = {
            "Comp√©tences": scores.get("skills_score", 0),
            "Exp√©rience": scores.get("experience_score", 0),
            "Formation": scores.get("education_score", 0),
            "Culture": culture_avg,
            "Entretien": interview_avg
        }
        radar_labels = list(radar_data.keys())
        radar_values = list(radar_data.values()) + [radar_data["Comp√©tences"]]
        ideal_values = [100] * len(radar_labels) + [100]
        angles = np.linspace(0, 2 * np.pi, len(radar_labels), endpoint=False).tolist()
        angles += angles[:1]
        plt.figure(figsize=(8, 8))
        ax = plt.subplot(111, polar=True)
        ax.fill(angles, ideal_values, color='lightgray', alpha=0.3, label='Profil id√©al')
        ax.fill(angles, radar_values, color='skyblue', alpha=0.5, label='Candidat')
        ax.plot(angles, radar_values, color='blue', linewidth=2)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(radar_labels)
        ax.set_title("Comparaison Candidat vs Profil Id√©al", size=14, y=1.08)
        plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))
        plt.savefig("predictive_radar.png")
        plt.close()

        report = {
            "predictive_score": predictive_score,
            "appreciations": appreciations,
            "risks": analysis["risks"],
            "recommendations": analysis["recommendations"],
            "radar_data": radar_data
        }

        with open("predictive_performance_report.json", "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        return report
    except Exception as e:
        return {"error": f"Erreur g√©n√©rale : {str(e)}"}

def cleanup_memory():
    """Nettoie la m√©moire en lib√©rant les ressources non utilis√©es."""
    global _model_instance
    
    # Lib√©rer le mod√®le s'il existe
    if _model_instance is not None:
        del _model_instance
        _model_instance = None
    
    # Lib√©rer la m√©moire CUDA si disponible
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # Forcer le garbage collector
    gc.collect()

def generate_fallback_questions(job_description, cv_data, score_result):
    """G√©n√®re des questions de fallback quand l'API √©choue"""
    
    job_title = job_description.get("title", "D√©veloppeur")
    job_skills = job_description.get("skills", [])
    cv_skills = cv_data.get("Comp√©tences", [])
    cv_education = cv_data.get("Formations", [{}])[0].get("dipl√¥me", "Formation non sp√©cifi√©e")
    
    # Questions techniques bas√©es sur le poste
    job_questions = [
        {"category": "Job Description", "question": f"Pouvez-vous me parler de votre exp√©rience avec {job_skills[0] if job_skills else 'les technologies principales'} ?", "purpose": "√âvaluer comp√©tences techniques"},
        {"category": "Job Description", "question": f"Comment aborderiez-vous un projet complexe en tant que {job_title} ?", "purpose": "√âvaluer approche m√©thodologique"},
        {"category": "Job Description", "question": "D√©crivez-moi un d√©fi technique que vous avez r√©cemment r√©solu et votre approche.", "purpose": "√âvaluer r√©solution de probl√®mes"},
        {"category": "Job Description", "question": f"Quelles sont selon vous les qualit√©s essentielles d'un bon {job_title} ?", "purpose": "√âvaluer compr√©hension du r√¥le"},
        {"category": "Job Description", "question": "Comment vous tenez-vous inform√© des derni√®res tendances dans votre domaine ?", "purpose": "√âvaluer curiosit√© technique"},
    ]
    
    # Questions culture d'entreprise
    culture_questions = [
        {"category": "Company Culture", "question": "Comment d√©finiriez-vous l'innovation dans votre travail quotidien ?", "purpose": "√âvaluer esprit d'innovation"},
        {"category": "Company Culture", "question": "D√©crivez une situation o√π vous avez d√ª collaborer √©troitement avec une √©quipe.", "purpose": "√âvaluer collaboration"},
        {"category": "Company Culture", "question": "Comment g√©rez-vous la communication dans un environnement de travail transparent ?", "purpose": "√âvaluer transparence"},
        {"category": "Company Culture", "question": "Donnez-moi un exemple de comment vous avez am√©lior√© l'exp√©rience d'un client/utilisateur.", "purpose": "√âvaluer orientation client"},
        {"category": "Company Culture", "question": "Comment vous adaptez-vous aux changements rapides dans un environnement startup ?", "purpose": "√âvaluer adaptabilit√©"},
    ]
    
    # Questions CV/Exp√©rience personnalis√©es
    cv_questions = []
    if cv_skills:
        cv_questions.append({"category": "CV/Professional Life", "question": f"Je vois que vous ma√Ætrisez {cv_skills[0]}. Pouvez-vous me donner un exemple concret d'utilisation ?", "purpose": "Approfondir comp√©tences"})
    else:
        cv_questions.append({"category": "CV/Professional Life", "question": "Parlez-moi de vos principales comp√©tences techniques.", "purpose": "Identifier comp√©tences"})
    
    cv_questions.extend([
        {"category": "CV/Professional Life", "question": f"Votre formation en {cv_education} vous a-t-elle pr√©par√© √† ce r√¥le ? Comment ?", "purpose": "√âvaluer formation"},
        {"category": "CV/Professional Life", "question": "D√©crivez-moi le projet dont vous √™tes le plus fier dans votre parcours.", "purpose": "Comprendre r√©alisations"},
        {"category": "CV/Professional Life", "question": "Quels sont vos objectifs de carri√®re √† moyen terme ?", "purpose": "Mesurer ambition"},
        {"category": "CV/Professional Life", "question": "Comment √©valuez-vous votre progression professionnelle jusqu'√† pr√©sent ?", "purpose": "Auto-√©valuation"},
    ])
    
    all_questions = job_questions + culture_questions + cv_questions
    
    return {"questions": all_questions}